# Attend and Rectify: a gated attention mechanism for fine-grained recovery
Code for the paper presented at ECCV2018

Contents:
```
./logs
    best logs for the tables reported in the paper
./scripts
    sh scripts to reproduce experiments
./modules
    contains the attention module proposed in the paper.
./models
    contains the different networks used on cifar.
```

Usage:
1. git clone this repository && cd this repository
2. ./scripts/your_script.sh (edit to set dataset paths, etc)

Requirements:
1. The code requires pytorch 0.4
